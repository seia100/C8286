# Detalles del Dise√±o y Arquitectura del Sistema Distribuido de Detecci√≥n de Intrusiones (IDS)

## 1. Requisitos del IDS

### 1.1 Tipos de Intrusiones a Detectar üïµÔ∏è‚Äç‚ôÇÔ∏è

El sistema debe ser capaz de detectar los siguientes tipos de intrusiones:

1. **Ataques de Fuerza Bruta**: Intentos repetidos de autenticaci√≥n fallidos.
2. **Escaneo de Puertos**: Detecci√≥n de escaneos sistem√°ticos de puertos en la red.
3. **Inyecci√≥n SQL**: Identificaci√≥n de patrones de inyecci√≥n SQL en las solicitudes HTTP.
4. **Cross-Site Scripting (XSS)**: Detecci√≥n de intentos de inyecci√≥n de scripts maliciosos.
5. **Denegaci√≥n de Servicio (DoS)**: Identificaci√≥n de patrones de tr√°fico anormales que puedan indicar un ataque DoS.
6. **Malware y Botnets**: Detecci√≥n de comunicaciones sospechosas que puedan indicar infecciones de malware o actividad de botnets.
7. **Exfiltraci√≥n de Datos**: Identificaci√≥n de transferencias de datos anormales que puedan indicar fuga de informaci√≥n.
8. **Man-in-the-Middle (MitM)**: Detecci√≥n de intentos de interceptaci√≥n de tr√°fico.

### 1.2 Umbrales de Alerta y Criterios de An√°lisis‚öôÔ∏è

Para cada tipo de intrusi√≥n, se establecer√°n los siguientes umbrales y criterios:

#### Umbrales y criterios obligatoriosüîí:
1. **Ataques de Fuerza Bruta**:
   - Umbral: M√°s de 5 intentos fallidos de autenticaci√≥n en 1 minuto.
   - Criterio: Monitoreo de logs de autenticaci√≥n y an√°lisis de patrones de intentos fallidos.
   - Metodolog√≠a: An√°lisis de series temporales con algoritmos ARIMA y detecci√≥n de outliers.

2. **Escaneo de Puertos**:
   - Umbral: M√°s de 100 intentos de conexi√≥n a diferentes puertos desde una misma IP en 5 minutos.
   - Criterio: An√°lisis de patrones de tr√°fico TCP/UDP.
   - Metodolog√≠a: Implementaci√≥n de algoritmos de detecci√≥n de patrones basados en grafos.

3. **Inyecci√≥n SQL**:
   - Umbral: Detecci√≥n de 3 o m√°s patrones sospechosos en solicitudes HTTP en 10 minutos.
   - Criterio: An√°lisis de payload de solicitudes HTTP utilizando expresiones regulares.
   - Metodolog√≠a: An√°lisis l√©xico y sint√°ctico de payloads HTTP utilizando √°rboles de parsing.

#### Umbrales a realizarse posteriormente üîì:
4. **Cross-Site Scripting (XSS)**:
   - Umbral: Detecci√≥n de 2 o m√°s intentos de inyecci√≥n de scripts en 5 minutos.
   - Criterio: An√°lisis de par√°metros de solicitudes HTTP y respuestas del servidor.
   - Metodolog√≠a: Implementaci√≥n de sanitizaci√≥n y an√°lisis de contexto de entrada de usuario.

5. **Denegaci√≥n de Servicio (DoS)**:
   - Umbral: Aumento del 200% en el tr√°fico normal hacia un servicio espec√≠fico en 1 minuto.
   - Criterio: An√°lisis estad√≠stico del volumen y patr√≥n de tr√°fico.
   - Metodolog√≠a: An√°lisis multivariante de caracter√≠sticas de tr√°fico y clasificaci√≥n mediante SVM.

6. **Malware y Botnets**:
   - Umbral: Detecci√≥n de 5 o m√°s conexiones a direcciones IP conocidas como maliciosas en 1 hora al host.
   - Criterio: Comparaci√≥n de tr√°fico con listas negras de IPs y dominios conocidos.
   - Metodolog√≠a: Implementaci√≥n de modelos de aprendizaje profundo para clasificaci√≥n de tr√°fico malicioso.

7. **Exfiltraci√≥n de Datos**:
   - Umbral: Transferencia de datos superior a 100MB hacia direcciones IP externas no autorizadas en 1 hora.
   - Criterio: An√°lisis de volumen y destino del tr√°fico saliente.
   - Metodolog√≠a: An√°lisis de flujo de datos mediante t√©cnicas de procesamiento de big data.

8. **Man-in-the-Middle (MitM)**:
   - Umbral: Detecci√≥n de 3 o m√°s intentos de ARP spoofing o DNS en 10 minutos por segmento de red.
   - Criterio: Monitoreo de tablas ARP y an√°lisis de cambios sospechosos.
   - Metodolog√≠a: Implementaci√≥n de algoritmos de detecci√≥n de anomal√≠as en protocolos de red.

### 1.3 Requisitos de Rendimiento y Disponibilidad üìà

1. **Rendimiento**:
   - Capacidad de procesar al menos 10,000 paquetes por segundo en tiempo real.
   - Latencia m√°xima de 100ms desde la captura del paquete hasta la generaci√≥n de una alerta.
   - Capacidad de escalar horizontalmente para manejar aumentos en el tr√°fico de red.
     - Throughput de an√°lisis: Capacidad de escalar linealmente con el aumento de nodos de procesamiento. 

2. **Disponibilidad**:
   - Tiempo de actividad del 99.99% (menos de 52 minutos de inactividad al a√±o).
     - SLA (Service Level Agreement) de tiempo de actividad: se espera en un caso ideal o en el mejor de los casos. 
   - Implementaci√≥n de redundancia en todos los componentes cr√≠ticos con redundancia N+1 en componentes cr√≠ticos.
     - importante mencionar que la implentacion de servicios o servidores sera con Docker y con un escalado proporcional gestionado por Kubernetes.Lo cual automatiza el escalado y, balanceo de carga y tolerancia a fallos.  
   - Capacidad de recuperaci√≥n autom√°tica en caso de fallo de un nodo.
   - Balanceo de carga entre m√∫ltiples instancias de cada microservicio.

3. **Almacenamiento**:
   - Capacidad de almacenar y analizar logs de al menos 30 d√≠as.
   - Tiempo de respuesta m√°ximo de 5 segundos para consultas hist√≥ricas.

4. **Escalabilidad**:
   - Capacidad de escalar autom√°ticamente basado en la carga del sistema.
   - Soporte para m√∫ltiples instancias de cada microservicio.

## 2. Arquitectura del Sistema usando Microservicios üèóÔ∏è

### 2.1 Divisi√≥n en Microservicios Independientes üîß

El sistema se dividir√° en los siguientes microservicios:

1. **Capturador de Paquetes (Packet Capture Service)**
2. **Analizador de Datos (Data Analysis Service)**
3. **Gestor de Alertas (Alert Manager Service)**
4. **Base de Datos (Database Service)**
5. **Interfaz de Usuario (UI Service)**
6. **Servicio de Autenticaci√≥n (Authentication Service)**
7. **Servicio de Configuraci√≥n (Configuration Service)**
8. **Servicio de Logs (Logging Service)**

### 2.2 Componentes Principales üóÇÔ∏è

#### 2.2.1 Capturador de Paquetes (Packet Capture Service)

**Responsabilidades**:
- Captura de tr√°fico de red en tiempo real utilizando t√©cnicas de bypass de kernel.
- Filtrado inicial de paquetes basado en reglas predefinidas.
   - Basado en BPF (Berkeley Packet Filter).
     
- Preprocesamiento y normalizacion de paquetes para su an√°lisis posterior.

**Tecnolog√≠as**:
- Contenedor Docker basado en imagen de Python con Scapy instalado
- ZeroMQ para la transmisi√≥n eficiente de paquetes.
- eBPF compilado dentro del contenedor para filtrado a nivel de kernel
- Apache Flink desplegado como Job en Kubernetes

**Escalabilidad**:
- Utilizar DaemonSets y nodeSelector para asegurar que las instancias de la aplicaci√≥n est√©n desplegadas en nodos con las capacidades necesarias.
-  Configurar securityContext y asignar recursos optimizados (CPU/memoria) para aplicaciones de alto rendimiento en captura de paquetes (opcional).
-   Implementar t√©cnicas de sharding y balanceo de carga para manejar grandes vol√∫menes de datos de manera distribuida y eficiente.
-   Aplicar NUMA-aware computing para mejorar el rendimiento en sistemas multi-core.
-   Utilizar Kubernetes para gestionar el escalado y la administraci√≥n de la infraestructura de manera eficiente.

#### 2.2.2 Analizador de Datos (Data Analysis Service)

**Responsabilidades**:
- An√°lisis en tiempo real de los paquetes capturados.
- Aplicaci√≥n de algoritmos de detecci√≥n de intrusiones.
   - Correlaci√≥n de eventos multi-fuente para detecci√≥n de amenazas avanzadas persistentes (APT). 
- Generaci√≥n de alertas basadas en los umbrales definidos.
   - An√°lisis heur√≠stico y modelos de machine learning. Dado la complejidad de la implementacion se considera en mejoras del proyecto (opcional).

**Tecnolog√≠as**:
- Python con bibliotecas como NumPy y Pandas para an√°lisis de datos.
- TensorFlow o PyTorch para modelos de _machine & deep learning_ avanzados.
- Apache Kafka desplegado como StatefulSet en Kubernetes.
- Apache Spark para procesamiento distribuido de datos a gran escala.
   - Apache Spark configurado como Spark-on-Kubernetes

**Escalabilidad**:
- Utilizar un Deployment con HorizontalPodAutoscaler para desplegar la aplicaci√≥n principal, asegurando que escale autom√°ticamente seg√∫n la demanda.
- Utilizar PersistentVolumeClaims para garantizar el almacenamiento persistente de modelos y datos temporales.
- Implementar NodeAffinity para desplegar pods que requieren GPU en nodos espec√≠ficos con capacidades de GPU.
- Utilizar Apache Spark para manejar el procesamiento distribuido de datos, aplicando t√©cnicas de _consistent hashing_ para una distribuci√≥n equitativa de la carga.
   - Aplicar t√©cnicas de paralelismo dentro de Spark para optimizar el rendimiento de las tareas de procesamiento de datos.
   - Configurar los entornos de ejecuci√≥n de Spark para aprovechar las capacidades de GPU cuando sea relevante para las tareas de machine learning.


#### 2.2.3 Gestor de Alertas (Alert Manager Service)

**Responsabilidades**:
- Recepci√≥n y procesamiento de alertas generadas por el Analizador de Datos.
   - Para reducci√≥n de falsos positivos.
- Correlaci√≥n de alertas para identificar patrones de ataque complejos.
   - Implementaci√≥n de workflows de respuesta automatizada a incidentes.
- Notificaci√≥n a los administradores a trav√©s de diversos canales (email, SMS, etc.).
   - Notificaci√≥n multi-canal con soporte para escalamiento y SLAs.

**Tecnolog√≠as**: (consideraciones)
- Contenedor Docker basado en Node.js
- RabbitMQ para la gesti√≥n de colas de mensajes de alertas, considero m√°s accesible para implementar. 
   - Apache Kafka para implementaci√≥n de arquitectura de mensajer√≠a distribuida. Ademas estrategisas como lo es MPI, _Actor Model_, Cola de mensajes.
   - Relacion con la informaci√≥n: [Message Queue](https://medium.com/@rcougil/software-colas-de-mensajes-qu%C3%A9-son-y-para-qu%C3%A9-sirven-1a1d8e7f63f3)
   - RabbitMQ desplegado como StatefulSet en Kubernetes.
- Rundeck para orquestaci√≥n de tareas de respuesta a incidentes.
   - Es importante mencionar e implementar t√©cnicas de [SOAR](https://www.ibm.com/es-es/topics/security-orchestration-automation-response) o tambi√©n se puede consultar el siguiente _link_: [Security Orchestration, Automation and Response](https://ciberseguridadmax.com/soar/)

**Escalabilidad**:
- Implementar un sistema de colas distribuido (por ejemplo, Apache Kafka o RabbitMQ) para gestionar picos de tr√°fico y alertas.
- Desplegar la aplicaci√≥n como un Deployment en Kubernetes con la estrategia de RollingUpdate para asegurar actualizaciones sin interrupciones.
- Configurar readinessProbe y livenessProbe para monitorear la salud de los pods y garantizar que solo los pods saludables manejen tr√°fico.
- Utilizar ConfigMaps para gestionar las configuraciones de la aplicaci√≥n, permitiendo cambios din√°micos y centralizados.
- Implementar PodDisruptionBudget para asegurar que siempre haya un n√∫mero m√≠nimo de pods disponibles durante actualizaciones o eventos de mantenimiento.


#### 2.2.4 Base de Datos (Database Service)
Servicio de Persistencia y Consulta de Datos (DPQS)

**Responsabilidades**:
- Almacenamiento persistente de logs, alertas y configuraciones.
- Gesti√≥n de consultas para an√°lisis hist√≥ricos y generaci√≥n de informes.
- Soporte para consultas complejas y an√°lisis forense (opcional)

**Tecnolog√≠as**:
- MongoDB para almacenamiento de datos no estructurados (logs y alertas).
   - MongoDB desplegado como StatefulSet en Kubernetes 
- PostgreSQL para datos estructurados (configuraciones y metadatos).
   - PostgreSQL desplegado como StatefulSet con operador espec√≠fico
- Redis para cach√© y almacenamiento en memoria de datos frecuentemente accedidos.
   - Redis desplegado como StatefulSet para cach√© distribuido 

**Escalabilidad**:
- Configurar StorageClass en Kubernetes para proporcionar almacenamiento persistente din√°micamente seg√∫n las necesidades de los pods.
- Implementar CronJobs para realizar backups autom√°ticos de los datos cr√≠ticos, asegurando la recuperaci√≥n de datos en caso de fallo.
- Implementar servicios headless para permitir la comunicaci√≥n directa entre los pods, mejorando la eficiencia.
- Configurar MongoDB con sharding basado en rangos temporales para distribuir los datos de manera eficiente.
- Implementar la replicaci√≥n de bases de datos para asegurar alta disponibilidad y mejorar el rendimiento de lectura.
- Utilizar t√©cnicas de compresi√≥n avanzada y tiering de almacenamiento para optimizar el uso y el rendimiento del almacenamiento.

#### 2.2.5 Interfaz de Usuario (UI Service)
Servicio de Interfaz de Usuario y Visualizaci√≥n (UIVS)

**Responsabilidades**:
- Presentaci√≥n de dashboards y visualizaciones de alertas y estad√≠sticas.
- Interfaz para configuraci√≥n del sistema y gesti√≥n de reglas de detecci√≥n.
- Visualizaci√≥n de logs y herramientas de b√∫squeda avanzada.

**Tecnolog√≠as**:
- React.js para el frontend, permitiendo una interfaz de usuario din√°mica y responsive. React con TypeScript para desarrollo de frontend robusto y tipado (tratare de interactuar con estas tecnolog√≠as). Caso contrario usar√© herremientas como lo es Dart(Flutter).
- Nginx como servidor web dentro del contenedor
- D3.js y WebGL para visualizaciones de datos de alto rendimiento.
- GraphQL y Apollo para una API flexible que permita consultas eficientes desde el frontend. Estos estaran contenerizados.

**Escalabilidad**:
- Implementaci√≥n de server-side rendering para mejorar el rendimiento.
   - Implementaci√≥n de t√©cnicas de Code Splitting y Lazy Loading para optimizaci√≥n de carga.
- Uso de [CDN](https://aws.amazon.com/es/what-is/cdn/) para distribuci√≥n global de assets est√°ticos. Es decir, la autilizacion de [_Edge Computing_](https://www.ibm.com/es-es/topics/edge-computing) para la distribucion global de contenido est√°tico y din√°mico nos permite ver diferentes directrices de desarrollo.


#### 2.2.6 Servicio de Autenticaci√≥n (Authentication Service)
Servicio de Autenticaci√≥n y Control de Acceso (AACS)

**Responsabilidades**:
- Gesti√≥n de autenticaci√≥n y autorizaci√≥n de usuarios basada en roles (RBAC) y atributos (ABAC)
- Implementaci√≥n de single sign-on (SSO) y multi-factor authentication (MFA).

**Tecnolog√≠as**:
- Contenedor Docker con implementaci√≥n de OAuth 2.0 y OpenID Connect
- Keycloak para gesti√≥n centralizada de identidad y acceso.
   - Keycloak desplegado como StatefulSet en Kubernetes
- LDAP y Active Directory para integraci√≥n con directorios corporativos.
   - Uso de ExternalName Service para integraci√≥n con LDAP/Active Directory externos

**Escalabilidad**:

- Uso de servicios de directorio distribuidos para almacenamiento de credenciales.
   - Caching distribuido de tokens y sesiones.
   - Configuraci√≥n de secretos para almacenamiento seguro de credenciales
- Implementaci√≥n de Network Policies para restringir acceso al servicio
- Uso de PodDisruptionBudget para garantizar alta disponibilidad
  
#### 2.2.7 Servicio de Configuraci√≥n (Configuration Service)
Servicio de Gesti√≥n de Configuraci√≥n y Pol√≠ticas (CPMS)

**Responsabilidades**:
- Gesti√≥n centralizada de configuraciones y politicas de seguridad para todos los microservicios.
- Actualizaciones din√°micas de configuraci√≥n sin necesidad de reiniciar servicios.
   - Versionado y rollback de configuraciones.
- 

**Tecnolog√≠as**:
- [_Spring Cloud Config_](https://spring.io/projects/spring-cloud-config) para gesti√≥n centralizada de configuraciones.
- [ZooKeeper](https://www.geeksforgeeks.org/what-is-apache-zookeeper/) para coordinaci√≥n distribuida y gesti√≥n de configuraciones din√°micas. 
- [etcd](https://www.ibm.com/topics/etcd) para almacenamiento distribuido de configuraciones.
   - Desplegar etcd como un StatefulSet en Kubernetes para el almacenamiento distribuido de configuraciones. 

**Escalabilidad**:
- Configurar la replicaci√≥n de configuraciones en m√∫ltiples nodos usando Spring Cloud Config, ZooKeeper y etcd para asegurar alta disponibilidad.
- Desplegar los servicios como Deployment con m√∫ltiples r√©plicas para mejorar la resiliencia y capacidad de manejo de carga.
  
#### 2.2.8 Servicio de Logs (Logging Service)

**Responsabilidades**:
- Recopilaci√≥n y almacenamiento centralizado de logs de todos los microservicios.
- Indexaci√≥n y b√∫squeda eficiente de logs para an√°lisis y debugging.

**Tecnolog√≠as**:
- ELK Stack (Elasticsearch, Logstash, Kibana) para gesti√≥n y visualizaci√≥n de logs. √âste debe ser deplegado en Kubernets
- Fluentd como DaemonSet para recolecci√≥n y forwarding de logs.

**Escalabilidad**:
- Clusterizaci√≥n de Elasticsearch para manejo de grandes vol√∫menes de logs.
- Elasticsearch desplegado como StatefulSet con configuraci√≥n de cluster.
   - Configuraci√≥n de recursos y l√≠mites para optimizar rendimiento del cluster ELK
- Kibana desplegado como Deployment con Ingress para acceso externo
- Uso de StorageClass para provisi√≥n din√°mica de almacenamiento para Elasticsearch


### 2.3 Interfaces y Protocolos de Comunicaci√≥n entre Microservicios

1. **API RESTful**:
   - Utilizada para la comunicaci√≥n entre la mayor√≠a de los microservicios.
   - Implementaci√≥n de OpenAPI (Swagger) para documentaci√≥n y pruebas de API.

2. **gRPC**:
   - Usado para comunicaci√≥n de alta eficiencia entre el Capturador de Paquetes y el Analizador de Datos.
   - Permite streaming bidireccional para procesamiento en tiempo real.

3. **Apache Kafka**:
   - Implementado para el streaming de datos entre el Analizador de Datos y el Gestor de Alertas.
   - Proporciona un buffer resiliente para manejar picos de tr√°fico.

4. **RabbitMQ**:
   - Utilizado para la gesti√≥n de colas de mensajes, especialmente para la distribuci√≥n de alertas.

5. **WebSocket**:
   - Implementado en la Interfaz de Usuario para actualizaciones en tiempo real de alertas y estad√≠sticas.
      - Utilizado por UIVS para actualizaciones en tiempo real de alertas y m√©tricas. 

6. **GraphQL**:
   - Utilizado por la Interfaz de Usuario para realizar consultas flexibles a los datos almacenados.
      - UIVS para realizar queries flexibles a DPQS.
   - Implementaci√≥n de Federation para composici√≥n de schemas distribuidos.

### 2.4 Seguridad en la Comunicaci√≥n

- Implementaci√≥n de TLS/SSL para todas las comunicaciones entre microservicios.
- Uso de mTLS (mutual TLS) para autenticaci√≥n y encriptaci√≥n mutua entre servicios.
- Implementaci√≥n de API Gateway para centralizar la autenticaci√≥n y autorizaci√≥n.
   - Tt√©cnicas de ofuscaci√≥n y tokenizaci√≥n para datos sensibles en tr√°nsito y reposo.
- Rotaci√≥n regular de claves y certificados.
   - Uso de protocolos como ACME

### 2.5 Monitoreo y Observabilidad

- Implementaci√≥n de Prometheus para la recolecci√≥n de m√©tricas de todos los microservicios.
- Uso de Grafana para la visualizaci√≥n de m√©tricas y creaci√≥n de dashboards.
- Implementaci√≥n de tracing distribuido con Jaeger para seguimiento de transacciones a trav√©s de m√∫ltiples servicios.
- Alertas autom√°ticas basadas en umbrales de rendimiento y disponibilidad.

### 2.6 Consideraciones Generales de Kubertenes

- Uso de Namespaces para separar entornos (desarrollo, staging, producci√≥n)
- Implementaci√≥n de Network Policies para seguridad entre servicios
- Configuraci√≥n de ResourceQuotas para limitar recursos por Namespace
- Uso de PriorityClasses para asegurar QoS en servicios cr√≠ticos
- Implementaci√≥n de Helm Charts para facilitar el despliegue y actualizaciones
- Configuraci√≥n de Prometheus y Grafana para monitoreo del cluster y aplicaciones
- Uso de Istio como service mesh para gesti√≥n avanzada de tr√°fico y seguridad (opcional)

## Conclusi√≥n

Esta arquitectura de microservicios para el Sistema Distribuido de Detecci√≥n de Intrusiones (IDS) est√° dise√±ada para proporcionar una soluci√≥n escalable, resiliente y de alto rendimiento. La divisi√≥n en microservicios independientes permite una mayor flexibilidad en el desarrollo, despliegue y escalado de componentes individuales. La implementaci√≥n de tecnolog√≠as modernas y protocolos eficientes asegura que el sistema pueda manejar grandes vol√∫menes de tr√°fico y detectar intrusiones en tiempo real. 

La arquitectura propuesta tambi√©n facilita la evoluci√≥n continua del sistema, permitiendo la integraci√≥n de nuevos algoritmos de detecci√≥n y la adaptaci√≥n a nuevas amenazas de seguridad. Con un enfoque en la observabilidad y el monitoreo, el sistema puede ser gestionado y optimizado de manera proactiva, asegurando un alto nivel de disponibilidad y rendimiento.
