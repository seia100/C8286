# Detalles del Dise帽o y Arquitectura del Sistema Distribuido de Detecci贸n de Intrusiones (IDS)

## 1. Requisitos del IDS

### 1.1 Tipos de Intrusiones a Detectar

El sistema debe ser capaz de detectar los siguientes tipos de intrusiones:

1. **Ataques de Fuerza Bruta**: Intentos repetidos de autenticaci贸n fallidos.
2. **Escaneo de Puertos**: Detecci贸n de escaneos sistem谩ticos de puertos en la red.
3. **Inyecci贸n SQL**: Identificaci贸n de patrones de inyecci贸n SQL en las solicitudes HTTP.
4. **Cross-Site Scripting (XSS)**: Detecci贸n de intentos de inyecci贸n de scripts maliciosos.
5. **Denegaci贸n de Servicio (DoS)**: Identificaci贸n de patrones de tr谩fico anormales que puedan indicar un ataque DoS.
6. **Malware y Botnets**: Detecci贸n de comunicaciones sospechosas que puedan indicar infecciones de malware o actividad de botnets.
7. **Exfiltraci贸n de Datos**: Identificaci贸n de transferencias de datos anormales que puedan indicar fuga de informaci贸n.
8. **Man-in-the-Middle (MitM)**: Detecci贸n de intentos de interceptaci贸n de tr谩fico.

### 1.2 Umbrales de Alerta y Criterios de An谩lisis

Para cada tipo de intrusi贸n, se establecer谩n los siguientes umbrales y criterios:

#### Umbrales y criterios obligatorios:
1. **Ataques de Fuerza Bruta**:
   - Umbral: M谩s de 5 intentos fallidos de autenticaci贸n en 1 minuto.
   - Criterio: Monitoreo de logs de autenticaci贸n y an谩lisis de patrones de intentos fallidos.
   - Metodolog铆a: An谩lisis de series temporales con algoritmos ARIMA y detecci贸n de outliers.

2. **Escaneo de Puertos**:
   - Umbral: M谩s de 100 intentos de conexi贸n a diferentes puertos desde una misma IP en 5 minutos.
   - Criterio: An谩lisis de patrones de tr谩fico TCP/UDP.
   - Metodolog铆a: Implementaci贸n de algoritmos de detecci贸n de patrones basados en grafos.

3. **Inyecci贸n SQL**:
   - Umbral: Detecci贸n de 3 o m谩s patrones sospechosos en solicitudes HTTP en 10 minutos.
   - Criterio: An谩lisis de payload de solicitudes HTTP utilizando expresiones regulares.
   - Metodolog铆a: An谩lisis l茅xico y sint谩ctico de payloads HTTP utilizando 谩rboles de parsing.

#### Umbrales a realizarse posteriormente :
4. **Cross-Site Scripting (XSS)**:
   - Umbral: Detecci贸n de 2 o m谩s intentos de inyecci贸n de scripts en 5 minutos.
   - Criterio: An谩lisis de par谩metros de solicitudes HTTP y respuestas del servidor.
   - Metodolog铆a: Implementaci贸n de sanitizaci贸n y an谩lisis de contexto de entrada de usuario.

5. **Denegaci贸n de Servicio (DoS)**:
   - Umbral: Aumento del 200% en el tr谩fico normal hacia un servicio espec铆fico en 1 minuto.
   - Criterio: An谩lisis estad铆stico del volumen y patr贸n de tr谩fico.
   - Metodolog铆a: An谩lisis multivariante de caracter铆sticas de tr谩fico y clasificaci贸n mediante SVM.

6. **Malware y Botnets**:
   - Umbral: Detecci贸n de 5 o m谩s conexiones a direcciones IP conocidas como maliciosas en 1 hora al host.
   - Criterio: Comparaci贸n de tr谩fico con listas negras de IPs y dominios conocidos.
   - Metodolog铆a: Implementaci贸n de modelos de aprendizaje profundo para clasificaci贸n de tr谩fico malicioso.

7. **Exfiltraci贸n de Datos**:
   - Umbral: Transferencia de datos superior a 100MB hacia direcciones IP externas no autorizadas en 1 hora.
   - Criterio: An谩lisis de volumen y destino del tr谩fico saliente.
   - Metodolog铆a: An谩lisis de flujo de datos mediante t茅cnicas de procesamiento de big data.

8. **Man-in-the-Middle (MitM)**:
   - Umbral: Detecci贸n de 3 o m谩s intentos de ARP spoofing o DNS en 10 minutos por segmento de red.
   - Criterio: Monitoreo de tablas ARP y an谩lisis de cambios sospechosos.
   - Metodolog铆a: Implementaci贸n de algoritmos de detecci贸n de anomal铆as en protocolos de red.

### 1.3 Requisitos de Rendimiento y Disponibilidad

1. **Rendimiento**:
   - Capacidad de procesar al menos 10,000 paquetes por segundo en tiempo real.
   - Latencia m谩xima de 100ms desde la captura del paquete hasta la generaci贸n de una alerta.
   - Capacidad de escalar horizontalmente para manejar aumentos en el tr谩fico de red.
     - Throughput de an谩lisis: Capacidad de escalar linealmente con el aumento de nodos de procesamiento. 

2. **Disponibilidad**:
   - Tiempo de actividad del 99.99% (menos de 52 minutos de inactividad al a帽o).
     - SLA (Service Level Agreement) de tiempo de actividad: se espera en un caso ideal o en el mejor de los casos. 
   - Implementaci贸n de redundancia en todos los componentes cr铆ticos con redundancia N+1 en componentes cr铆ticos.
     - importante mencionar que la implentacion de servicios o servidores sera con Docker y con un escalado proporcional gestionado por Kubernetes.Lo cual automatiza el escalado y, balanceo de carga y tolerancia a fallos.  
   - Capacidad de recuperaci贸n autom谩tica en caso de fallo de un nodo.
   - Balanceo de carga entre m煤ltiples instancias de cada microservicio.

3. **Almacenamiento**:
   - Capacidad de almacenar y analizar logs de al menos 30 d铆as.
   - Tiempo de respuesta m谩ximo de 5 segundos para consultas hist贸ricas.

4. **Escalabilidad**:
   - Capacidad de escalar autom谩ticamente basado en la carga del sistema.
   - Soporte para m煤ltiples instancias de cada microservicio.

## 2. Arquitectura del Sistema usando Microservicios

### 2.1 Divisi贸n en Microservicios Independientes

El sistema se dividir谩 en los siguientes microservicios:

1. **Capturador de Paquetes (Packet Capture Service)**
2. **Analizador de Datos (Data Analysis Service)**
3. **Gestor de Alertas (Alert Manager Service)**
4. **Base de Datos (Database Service)**
5. **Interfaz de Usuario (UI Service)**
6. **Servicio de Autenticaci贸n (Authentication Service)**
7. **Servicio de Configuraci贸n (Configuration Service)**
8. **Servicio de Logs (Logging Service)**

### 2.2 Componentes Principales

#### 2.2.1 Capturador de Paquetes (Packet Capture Service)

**Responsabilidades**:
- Captura de tr谩fico de red en tiempo real utilizando t茅cnicas de bypass de kernel.
- Filtrado inicial de paquetes basado en reglas predefinidas.
   - Basado en BPF (Berkeley Packet Filter).
     
- Preprocesamiento y normalizacion de paquetes para su an谩lisis posterior.

**Tecnolog铆as**:
- Contenedor Docker basado en imagen de Python con Scapy instalado
- ZeroMQ para la transmisi贸n eficiente de paquetes.
- eBPF compilado dentro del contenedor para filtrado a nivel de kernel
- Apache Flink desplegado como Job en Kubernetes

**Escalabilidad**:
- Utilizar DaemonSets y nodeSelector para asegurar que las instancias de la aplicaci贸n est茅n desplegadas en nodos con las capacidades necesarias.
-  Configurar securityContext y asignar recursos optimizados (CPU/memoria) para aplicaciones de alto rendimiento en captura de paquetes (opcional).
-   Implementar t茅cnicas de sharding y balanceo de carga para manejar grandes vol煤menes de datos de manera distribuida y eficiente.
-   Aplicar NUMA-aware computing para mejorar el rendimiento en sistemas multi-core.
-   Utilizar Kubernetes para gestionar el escalado y la administraci贸n de la infraestructura de manera eficiente.

#### 2.2.2 Analizador de Datos (Data Analysis Service)

**Responsabilidades**:
- An谩lisis en tiempo real de los paquetes capturados.
- Aplicaci贸n de algoritmos de detecci贸n de intrusiones.
   - Correlaci贸n de eventos multi-fuente para detecci贸n de amenazas avanzadas persistentes (APT). 
- Generaci贸n de alertas basadas en los umbrales definidos.
   - An谩lisis heur铆stico y modelos de machine learning. Dado la complejidad de la implementacion se considera en mejoras del proyecto (opcional).

**Tecnolog铆as**:
- Python con bibliotecas como NumPy y Pandas para an谩lisis de datos.
- TensorFlow o PyTorch para modelos de _machine & deep learning_ avanzados.
- Apache Kafka desplegado como StatefulSet en Kubernetes.
- Apache Spark para procesamiento distribuido de datos a gran escala.
   - Apache Spark configurado como Spark-on-Kubernetes

**Escalabilidad**:
- Utilizar un Deployment con HorizontalPodAutoscaler para desplegar la aplicaci贸n principal, asegurando que escale autom谩ticamente seg煤n la demanda.
- Utilizar PersistentVolumeClaims para garantizar el almacenamiento persistente de modelos y datos temporales.
- Implementar NodeAffinity para desplegar pods que requieren GPU en nodos espec铆ficos con capacidades de GPU.
- Utilizar Apache Spark para manejar el procesamiento distribuido de datos, aplicando t茅cnicas de _consistent hashing_ para una distribuci贸n equitativa de la carga.
   - Aplicar t茅cnicas de paralelismo dentro de Spark para optimizar el rendimiento de las tareas de procesamiento de datos.
   - Configurar los entornos de ejecuci贸n de Spark para aprovechar las capacidades de GPU cuando sea relevante para las tareas de machine learning.


#### 2.2.3 Gestor de Alertas (Alert Manager Service)

**Responsabilidades**:
- Recepci贸n y procesamiento de alertas generadas por el Analizador de Datos.
   - Para reducci贸n de falsos positivos.
- Correlaci贸n de alertas para identificar patrones de ataque complejos.
   - Implementaci贸n de workflows de respuesta automatizada a incidentes.
- Notificaci贸n a los administradores a trav茅s de diversos canales (email, SMS, etc.).
   - Notificaci贸n multi-canal con soporte para escalamiento y SLAs.

**Tecnolog铆as**: (consideraciones)
- Contenedor Docker basado en Node.js
- RabbitMQ para la gesti贸n de colas de mensajes de alertas, considero m谩s accesible para implementar. 
   - Apache Kafka para implementaci贸n de arquitectura de mensajer铆a distribuida. Ademas estrategisas como lo es MPI, _Actor Model_, Cola de mensajes.
   - Relacion con la informaci贸n: [Message Queue](https://medium.com/@rcougil/software-colas-de-mensajes-qu%C3%A9-son-y-para-qu%C3%A9-sirven-1a1d8e7f63f3)
   - RabbitMQ desplegado como StatefulSet en Kubernetes.
- Rundeck para orquestaci贸n de tareas de respuesta a incidentes.
   - Es importante mencionar e implementar t茅cnicas de [SOAR](https://www.ibm.com/es-es/topics/security-orchestration-automation-response) o tambi茅n se puede consultar el siguiente _link_: [Security Orchestration, Automation and Response](https://ciberseguridadmax.com/soar/)

**Escalabilidad**:
- Implementar un sistema de colas distribuido (por ejemplo, Apache Kafka o RabbitMQ) para gestionar picos de tr谩fico y alertas.
- Desplegar la aplicaci贸n como un Deployment en Kubernetes con la estrategia de RollingUpdate para asegurar actualizaciones sin interrupciones.
- Configurar readinessProbe y livenessProbe para monitorear la salud de los pods y garantizar que solo los pods saludables manejen tr谩fico.
- Utilizar ConfigMaps para gestionar las configuraciones de la aplicaci贸n, permitiendo cambios din谩micos y centralizados.
- Implementar PodDisruptionBudget para asegurar que siempre haya un n煤mero m铆nimo de pods disponibles durante actualizaciones o eventos de mantenimiento.


#### 2.2.4 Base de Datos (Database Service)
Servicio de Persistencia y Consulta de Datos (DPQS)

**Responsabilidades**:
- Almacenamiento persistente de logs, alertas y configuraciones.
- Gesti贸n de consultas para an谩lisis hist贸ricos y generaci贸n de informes.
- Soporte para consultas complejas y an谩lisis forense (opcional)

**Tecnolog铆as**:
- MongoDB para almacenamiento de datos no estructurados (logs y alertas).
   - MongoDB desplegado como StatefulSet en Kubernetes 
- PostgreSQL para datos estructurados (configuraciones y metadatos).
   - PostgreSQL desplegado como StatefulSet con operador espec铆fico
- Redis para cach茅 y almacenamiento en memoria de datos frecuentemente accedidos.
   - Redis desplegado como StatefulSet para cach茅 distribuido 

**Escalabilidad**:
- Configurar StorageClass en Kubernetes para proporcionar almacenamiento persistente din谩micamente seg煤n las necesidades de los pods.
- Implementar CronJobs para realizar backups autom谩ticos de los datos cr铆ticos, asegurando la recuperaci贸n de datos en caso de fallo.
- Implementar servicios headless para permitir la comunicaci贸n directa entre los pods, mejorando la eficiencia.
- Configurar MongoDB con sharding basado en rangos temporales para distribuir los datos de manera eficiente.
- Implementar la replicaci贸n de bases de datos para asegurar alta disponibilidad y mejorar el rendimiento de lectura.
- Utilizar t茅cnicas de compresi贸n avanzada y tiering de almacenamiento para optimizar el uso y el rendimiento del almacenamiento.

#### 2.2.5 Interfaz de Usuario (UI Service)
Servicio de Interfaz de Usuario y Visualizaci贸n (UIVS)

**Responsabilidades**:
- Presentaci贸n de dashboards y visualizaciones de alertas y estad铆sticas.
- Interfaz para configuraci贸n del sistema y gesti贸n de reglas de detecci贸n.
- Visualizaci贸n de logs y herramientas de b煤squeda avanzada.

**Tecnolog铆as**:
- React.js para el frontend, permitiendo una interfaz de usuario din谩mica y responsive. React con TypeScript para desarrollo de frontend robusto y tipado (tratare de interactuar con estas tecnolog铆as). Caso contrario usar茅 herremientas como lo es Dart(Flutter).
- D3.js y WebGL para visualizaciones de datos de alto rendimiento.
- GraphQL ocn Apollo para una API flexible que permita consultas eficientes desde el frontend.

**Escalabilidad**:
- Implementaci贸n de server-side rendering para mejorar el rendimiento.
   - Implementaci贸n de t茅cnicas de Code Splitting y Lazy Loading para optimizaci贸n de carga.
- Uso de [CDN](https://aws.amazon.com/es/what-is/cdn/) para distribuci贸n global de assets est谩ticos. Es decir, la autilizacion de [_Edge Computing_](https://www.ibm.com/es-es/topics/edge-computing) para la distribucion global de contenido est谩tico y din谩mico nos permite ver diferentes directrices de desarrollo.


#### 2.2.6 Servicio de Autenticaci贸n (Authentication Service)
Servicio de Autenticaci贸n y Control de Acceso (AACS)

**Responsabilidades**:
- Gesti贸n de autenticaci贸n y autorizaci贸n de usuarios basada en roles (RBAC) y atributos (ABAC)
- Implementaci贸n de single sign-on (SSO) y multi-factor authentication (MFA).

**Tecnolog铆as**:
- OAuth 2.0 y OpenID Connect para autenticaci贸n segura.
- Keycloak para gesti贸n centralizada de identidad y acceso.
- JWT (JSON Web Tokens) para manejo de sesiones.
- LDAP y Active Directory para integraci贸n con directorios corporativos.

**Escalabilidad**:
- Uso de servicios de directorio distribuidos para almacenamiento de credenciales.
   - Caching distribuido de tokens y sesiones.
- 
#### 2.2.7 Servicio de Configuraci贸n (Configuration Service)
Servicio de Gesti贸n de Configuraci贸n y Pol铆ticas (CPMS)

**Responsabilidades**:
- Gesti贸n centralizada de configuraciones y politicas de seguridad para todos los microservicios.
- Actualizaciones din谩micas de configuraci贸n sin necesidad de reiniciar servicios.
   - Versionado y rollback de configuraciones.
- 

**Tecnolog铆as**:
- [_Spring Cloud Config_](https://spring.io/projects/spring-cloud-config) para gesti贸n centralizada de configuraciones.
- [ZooKeeper](https://www.geeksforgeeks.org/what-is-apache-zookeeper/) para coordinaci贸n distribuida y gesti贸n de configuraciones din谩micas. Tambi茅n considerar [Consul] 
- [etcd](https://www.ibm.com/topics/etcd) para almacenamiento distribuido de configuraciones.

**Escalabilidad**:
- Replicaci贸n de configuraciones en m煤ltiples nodos para alta disponibilidad.

#### 2.2.8 Servicio de Logs (Logging Service)

**Responsabilidades**:
- Recopilaci贸n y almacenamiento centralizado de logs de todos los microservicios.
- Indexaci贸n y b煤squeda eficiente de logs para an谩lisis y debugging.

**Tecnolog铆as**:
- ELK Stack (Elasticsearch, Logstash, Kibana) para gesti贸n y visualizaci贸n de logs.
- Fluentd para recolecci贸n y forwarding de logs.

**Escalabilidad**:
- Clusterizaci贸n de Elasticsearch para manejo de grandes vol煤menes de logs.

### 2.3 Interfaces y Protocolos de Comunicaci贸n entre Microservicios

1. **API RESTful**:
   - Utilizada para la comunicaci贸n entre la mayor铆a de los microservicios.
   - Implementaci贸n de OpenAPI (Swagger) para documentaci贸n y pruebas de API.

2. **gRPC**:
   - Usado para comunicaci贸n de alta eficiencia entre el Capturador de Paquetes y el Analizador de Datos.
   - Permite streaming bidireccional para procesamiento en tiempo real.

3. **Apache Kafka**:
   - Implementado para el streaming de datos entre el Analizador de Datos y el Gestor de Alertas.
   - Proporciona un buffer resiliente para manejar picos de tr谩fico.

4. **RabbitMQ**:
   - Utilizado para la gesti贸n de colas de mensajes, especialmente para la distribuci贸n de alertas.

5. **WebSocket**:
   - Implementado en la Interfaz de Usuario para actualizaciones en tiempo real de alertas y estad铆sticas.
      - Utilizado por UIVS para actualizaciones en tiempo real de alertas y m茅tricas. 

6. **GraphQL**:
   - Utilizado por la Interfaz de Usuario para realizar consultas flexibles a los datos almacenados.
      - UIVS para realizar queries flexibles a DPQS.
   - Implementaci贸n de Federation para composici贸n de schemas distribuidos.

### 2.4 Seguridad en la Comunicaci贸n

- Implementaci贸n de TLS/SSL para todas las comunicaciones entre microservicios.
- Uso de mTLS (mutual TLS) para autenticaci贸n y encriptaci贸n mutua entre servicios.
- Implementaci贸n de API Gateway para centralizar la autenticaci贸n y autorizaci贸n.
   - Tt茅cnicas de ofuscaci贸n y tokenizaci贸n para datos sensibles en tr谩nsito y reposo.
- Rotaci贸n regular de claves y certificados.
   - Uso de protocolos como ACME

### 2.5 Monitoreo y Observabilidad

- Implementaci贸n de Prometheus para la recolecci贸n de m茅tricas de todos los microservicios.
- Uso de Grafana para la visualizaci贸n de m茅tricas y creaci贸n de dashboards.
- Implementaci贸n de tracing distribuido con Jaeger para seguimiento de transacciones a trav茅s de m煤ltiples servicios.
- Alertas autom谩ticas basadas en umbrales de rendimiento y disponibilidad.

## Conclusi贸n

Esta arquitectura de microservicios para el Sistema Distribuido de Detecci贸n de Intrusiones (IDS) est谩 dise帽ada para proporcionar una soluci贸n escalable, resiliente y de alto rendimiento. La divisi贸n en microservicios independientes permite una mayor flexibilidad en el desarrollo, despliegue y escalado de componentes individuales. La implementaci贸n de tecnolog铆as modernas y protocolos eficientes asegura que el sistema pueda manejar grandes vol煤menes de tr谩fico y detectar intrusiones en tiempo real. 

La arquitectura propuesta tambi茅n facilita la evoluci贸n continua del sistema, permitiendo la integraci贸n de nuevos algoritmos de detecci贸n y la adaptaci贸n a nuevas amenazas de seguridad. Con un enfoque en la observabilidad y el monitoreo, el sistema puede ser gestionado y optimizado de manera proactiva, asegurando un alto nivel de disponibilidad y rendimiento.
